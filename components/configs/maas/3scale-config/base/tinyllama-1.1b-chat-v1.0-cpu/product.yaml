apiVersion: capabilities.3scale.net/v1beta1
kind: Product
metadata:
  name: tinyllama-cpu
spec:
  name: "TinyLlama on CPU"
  systemName: "tinyllama-cpu"
  deployment:
    apicastHosted:
      authentication:
        userkey:
          authUserKey: "Authorization"
          credentials: "authorization"
  description: >
    A compact 1.1B parameter chat model using the same architecture and tokenizer as Llama 2. Trained on UltraChat and UltraFeedback datasets with DPO alignment. Designed for applications with restricted computation and memory footprint, plug-and-play compatible with Llama-based projects.
  backendUsages:
    tinyllama-cpu:
      path: /
  metrics:
    hits:
      description: Number of API hits
      friendlyName: Hits
      unit: "hit"
    total_tokens:
      description: Number of total tokens
      friendlyName: Total Tokens
      unit: "token"
    prompt_tokens:
      description: Number of prompt tokens
      friendlyName: Prompt Tokens
      unit: "token"
    completion_tokens:
      description: Number of completion tokens
      friendlyName: Completion Tokens
      unit: "token"
  methods:
    health:
      friendlyName: "Health Check"
      description: "Check the health of the model"
    tokenize:
      friendlyName: "Tokenize"
      description: "Tokenize the input text"
    detokenize:
      friendlyName: "Detokenize"
      description: "Detokenize the input text"
    models:
      friendlyName: "Models"
      description: "Get the list of models"
    version:
      friendlyName: "Version Check"
      description: "Check the version of the model"
    chat/completions:
      friendlyName: "Chat Completions"
      description: "Get the completions for the input text"
    completions:
      friendlyName: "Completions"
      description: "Get the completions for the input text"
    embeddings:
      friendlyName: "Embeddings"
      description: "Get the embeddings for the input text"
  mappingRules:
    - httpMethod: GET
      pattern: /health
      metricMethodRef: health
      increment: 1
    - httpMethod: POST
      pattern: /tokenize
      metricMethodRef: tokenize
      increment: 1
    - httpMethod: POST
      pattern: /detokenize
      metricMethodRef: detokenize
      increment: 1
    - httpMethod: GET
      pattern: /v1/models
      metricMethodRef: models
      increment: 1
    - httpMethod: GET
      pattern: /version
      metricMethodRef: version
      increment: 1
    - httpMethod: POST
      pattern: /v1/chat/completions
      metricMethodRef: chat/completions
      increment: 1
    - httpMethod: POST
      pattern: /v1/completions
      metricMethodRef: completions
      increment: 1
    - httpMethod: POST
      pattern: /v1/embeddings
      metricMethodRef: embeddings
      increment: 1
  applicationPlans:
    standard:
      name: "Standard"
      default: true
      appsRequireApproval: false
      published: true
  policies:
    - name: cors
      version: builtin
      enabled: true
      configuration:
        {
          "allow_origin": "*",
          "allow_headers": ["Authorization", "Content-type", "Accept"],
          "allow_methods": [],
        }
    - name: llm-metrics
      version: "0.1"
      enabled: true
      configuration:
        {
          "rules":
            [
              {
                "increment": "{{ llm_usage.total_tokens }}",
                "condition":
                  {
                    "operations":
                      [
                        {
                          "right_type": "plain",
                          "left_type": "liquid",
                          "left": "{{status}}",
                          "right": "200",
                          "op": "==",
                        },
                      ],
                    "combine_op": "and",
                  },
                "metric": "total_tokens",
              },
              {
                "increment": "{{ llm_usage.prompt_tokens }}",
                "condition":
                  {
                    "operations":
                      [
                        {
                          "right_type": "plain",
                          "left_type": "liquid",
                          "left": "{{status}}",
                          "right": "200",
                          "op": "==",
                        },
                      ],
                    "combine_op": "and",
                  },
                "metric": "prompt_tokens",
              },
              {
                "increment": "{{ llm_usage.completion_tokens }}",
                "condition":
                  {
                    "operations":
                      [
                        {
                          "right_type": "plain",
                          "left_type": "liquid",
                          "left": "{{status}}",
                          "right": "200",
                          "op": "==",
                        },
                      ],
                    "combine_op": "and",
                  },
                "metric": "completion_tokens",
              },
            ],
          "enable_sse_support": true,
        }
    - name: apicast
      version: "builtin"
      configuration: {}
      enabled: true
